# 异构系统并行

上述的方法中，通常需要大量的 GPU 来训练一个大型模型。然而，人们常常忽略一点，与 GPU 相比，CPU 的内存要大得多。在一个典型的服务器上，CPU 可以轻松拥有几百GB甚至上TB的内存，而每张 GPU 卡通常只有 40 或 80 GB的内存。因此可以利用 CPU 内存甚至是 NVMe 磁盘来进行分布式训练（在不使用张量时，将其卸载回 CPU 内存或 NVMe 磁盘）。

通过使用异构系统架构，有可能在一台机器上容纳一个巨大的模型。

<figure><img src="../../.gitbook/assets/image (2).png" alt=""><figcaption></figcaption></figure>

异构系统并行让 **GPU** 和 **CPU**协同工作：

* **GPU 的角色：** **计算单元**。它速度快，但显存（VRAM）昂贵且有限。
* **CPU 的角色：** **存储单元 + 辅助计算**。它的内存（RAM）便宜且巨大。

#### 异构系统并行机制

1. **存储阶段：** 模型的大部分参数、梯度和优化器状态平时都保存在 **CPU 内存**中。
2. **加载阶段：** 当 GPU 需要计算某一层时，才通过 PCIe 总线将这部分数据从 CPU 传输到 GPU 显存。
3. **计算阶段：** GPU 完成前向传播或反向传播的计算。
4. **卸载阶段（Offload）：** 计算完成后，GPU 立即将结果或不再需要的参数传回 CPU，释放 GPU 显存给下一层使用。

如果模型大到连 CPU 内存都装不下（如万亿参数模型），系统可以将数据进一步卸载到高速 NVMe SSD 硬盘上。虽然速度比内存更慢，但它提供了近乎无限的存储空间，理论上可以在单机上微调极其巨大的模型。

这是一种“以时间换空间”的策略

* **优点：** 极大地降低了训练大模型的门槛。可以在单张 24GB 显存的卡上微调很大的模型。
* **缺点：** 训练速度会变慢。因为 CPU 和 GPU 之间的数据传输（PCIe 带宽）成为了瓶颈，且 CPU 的计算速度远不如 GPU。
