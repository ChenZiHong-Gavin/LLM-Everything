# 📃 前言

<figure><img src=".gitbook/assets/Gemini_Generated_Image_nvoawnnvoawnnvoa.png" alt=""><figcaption></figcaption></figure>

[![GitBook](https://img.shields.io/static/v1?message=Documented%20on%20GitBook\&logo=gitbook\&logoColor=ffffff\&label=%20\&labelColor=5c5c5c\&color=3F89A1)](https://chenzihong.gitbook.io/llm-everything)

### 🌟在这里学习LLM，你将获得

* **超生动形象的技术讲解** ：我们摒弃了那些充斥着大量简单复制粘贴以及生硬 AI 合成内容的技术博客，每一篇技术文章都经过精心打磨，让你轻松理解复杂的知识。
* **超有料的技术实战** ：从零开始一步步实现代码，带你在实战中深入探究原理，真正掌握 LLM 的精髓。

### 📚 LLM知识地图

* 基础部分
  * Python基础
    * logging模块 ([logging.md](basics/python-basics/logging.md "mention"))
    * import模块 ([import.md](basics/python-basics/import.md "mention"))
    * multiprocessing模块( [multiprocessing.md](basics/python-basics/multiprocessing.md "mention"))
  * 机器学习基础
    * 特征提取
      * 文本表示模型
        * Bag-of-words ([bag-of-words.md](basics/machine-learning-basics/feature-extraction/text-representation-models/bag-of-words.md "mention"))
          * Topic Model ([topic-model.md](basics/machine-learning-basics/feature-extraction/text-representation-models/topic-model.md "mention"))
          * Static Word Embedding ( [static-word-embeddings.md](basics/machine-learning-basics/feature-extraction/text-representation-models/static-word-embeddings.md "mention"))
  * 深度学习基础
  * LLM基础
* **Transformer结构**
  * Tokenizer ([tokenizer.md](transformer/tokenizer.md "mention"))
  * Embedding ([embeddings](transformer/embeddings/ "mention"))
    * EMLO ([elmo.md](transformer/embeddings/elmo.md "mention"))
    * BERT ([bert.md](transformer/embeddings/bert.md "mention"))
    * GPT ([gpt.md](transformer/embeddings/gpt.md "mention"))
  * Positional Encoding ([positional-encoding.md](transformer/positional-encoding.md "mention"))
  * Self Attention ([self-attention.md](transformer/self-attention.md "mention"))
  * Multi-Head Attention ( [multi-head-attention.md](transformer/multi-head-attention.md "mention"))
  * Add & Norm (WIP)
  * FeedForward ( [feedforward.md](transformer/feedforward.md "mention")）
* Prompt工程
* 模型训练
  * LLM显存需求 ([llm-vram-needs](train/llm-vram-needs/ "mention"))
    * LLM精度问题 ([llm-precision.md](train/llm-vram-needs/llm-precision.md "mention"))
    * LLM训练需要多少显存 ([vram\_needs\_for\_llm\_training.md](train/llm-vram-needs/vram_needs_for_llm_training.md "mention"))
* 模型推理/部署
* MoE
  * 专家并行 ([expert-parallelism.md](moe/expert-parallelism.md "mention"))
* 知识编辑
* LLM应用
  * RAG
    * Graph RAG
* 多模态大模型
* LLM安全

### 🤝 与社区一起成长

本文档正在快速迭代中。\
分享你的见解，提出你的疑问，共同进步。
